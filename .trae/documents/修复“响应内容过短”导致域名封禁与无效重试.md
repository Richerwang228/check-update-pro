## 问题概览
- 触发源：`services.web_scraper` 在 `web_scraper.py:282` 以“内容长度 < 1000”判定为失败并调用 `request_manager.record_request(domain, False)`，导致连续重试与封禁。
- 封禁机制：`services.request_manager` 在 `request_manager.py:111-121` 连续失败≥3次，指数增加封禁时长（30s→60s→120s→…）。
- 结果：对 `hsex.men` 返回 200 但内容较短（可能为占位/挑战页）时，被误判为失败，重试与封禁不断升级。

## 修复目标
1. 避免单纯以“长度<1000”误判有效页面。
2. 减少“短内容”导致的失败计数与封禁升级。
3. 提高对反爬/占位页的识别与应对能力。

## 技术改动
### 1) 引入域名感知的页面有效性判断
- 新增 `is_valid_html_for_domain(domain: str, html: str) -> bool`：
  - 对 `hsex.men` 检查是否包含 `parse_video_info` 已使用的关键选择器或标识（如 `.col-xs-6.col-md-3`、`.thumbnail`、`.video-item` 等）。
  - 若存在这些结构，即使长度较短也判为有效。
  - 若不存在结构但包含典型错误/挑战标记（如 `cloudflare`、`just a moment`、`enable javascript`、`checking your browser`），判为无效。

### 2) 将“短内容”改为软失败并设定阈值
- 在 `get_page_content` 的 200 成功分支中：
  - 替换现有的 `len(response.text) < 1000` 直接失败逻辑。
  - 逻辑改为：
    - 若 `is_valid_html_for_domain` 为真：`record_request(domain, True)` 并返回。
    - 若为假且 `len(html) < threshold`：标记为软失败，记录 `short_content_streak += 1`。
      - 在 `short_content_streak < 3` 时：仅换代理/增加等待，不计入 `record_request(..., False)`。
      - 当 `short_content_streak >= 3`：才记一次硬失败 `record_request(..., False)` 并切换代理与延迟。
  - `short_content_streak` 在遇到有效页面后重置。
- 阈值策略：
  - 默认阈值可从 1000 下调到 300-500；
  - 也可引入 `domain_min_length = { 'hsex.men': 300 }` 的域名映射。

### 3) 增强请求头以模拟真实浏览器
- 在现有 UA 与 `sec-ch-ua` 基础上，增加：
  - `Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8`
  - `Accept-Language: zh-CN,zh;q=0.9,en;q=0.8`
  - `Upgrade-Insecure-Requests: 1`
  - `DNT: 1`
- 可选：当首次短内容出现时，附加 `Cache-Control: no-cache`、`Pragma: no-cache` 再试一次，以避免缓存占位页。

### 4) 细化日志与诊断
- 在短内容分支记录：域名、内容长度、`short_content_streak`、前 200 字符片段（便于进一步定位）。
- 将 Cloudflare/403/429 与短内容的日志区分更明显，避免误解。

### 5) 保持封禁逻辑不变，但减少误计数
- 不改动 `request_manager` 的封禁规则。
- 通过“软失败阈值”减少将短内容立刻计入 `record_request(..., False)` 的次数，避免误封禁。

## 实施步骤
1. 在 `services/web_scraper.py` 中新增 `is_valid_html_for_domain`，复用 `parse_video_info` 的选择器集合。
2. 改写 `200` 响应分支的短内容判定与处理为“域名感知 + 软失败阈值”。
3. 增加请求头字段；首次短内容时进行一次不缓存重试。
4. 调整并丰富日志输出，确保可观测性。
5. 本地运行并验证：
   - 对 `hsex.men` 连续请求，观察是否不再快速封禁；
   - 检查“短内容但含有效结构”能被接受；
   - 验证当确为占位/挑战页时，仍能在达到阈值后稳妥降级与重试。

## 影响与回退
- 影响：减少误失败与封禁次数；重试次数与等待策略更智能。
- 风险：若阈值过低可能接受错误页面；通过域名结构校验降低风险。
- 回退：保留原长度阈值与逻辑开关，可通过配置快速恢复旧行为。

## 交付物
- 更新后的 `web_scraper.py`（新增域名感知校验与软失败机制）。
- 可选：配置阈值映射与日志增强。