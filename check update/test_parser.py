#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ›´æ–°åçš„è§£æå™¨
éªŒè¯æ˜¯å¦å¯ä»¥æ­£ç¡®è§£æhsex.menç½‘ç«™çš„è§†é¢‘ä¿¡æ¯
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.web_scraper import WebScraper
from bs4 import BeautifulSoup

def test_parser():
    """æµ‹è¯•è§£æå™¨"""
    print("ğŸ§ª æµ‹è¯•æ›´æ–°åçš„è§£æå™¨...")
    
    # è¯»å–ä¹‹å‰ä¿å­˜çš„HTMLæ–‡ä»¶
    try:
        with open('user_page.html', 'r', encoding='utf-8') as f:
            html = f.read()
        print("ğŸ“„ ä½¿ç”¨å·²ä¿å­˜çš„HTMLæ–‡ä»¶è¿›è¡Œæµ‹è¯•")
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°user_page.htmlï¼Œè¯·å…ˆè¿è¡Œanalyze_user_page.py")
        return
    
    # åˆ›å»ºè§£æå™¨å®ä¾‹
    scraper = WebScraper()
    
    # æµ‹è¯•è§£æ
    videos = scraper.parse_video_info(html, "https://hsex.men")
    
    print(f"\nâœ… è§£æå®Œæˆï¼æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
    
    if videos:
        print("\nğŸ“‹ è§£æç»“æœ:")
        for i, video in enumerate(videos[:5]):
            print(f"\n{i+1}. è§†é¢‘ä¿¡æ¯:")
            print(f"   ğŸ“¹ ID: {video.get('video_id', 'æ— ')}")
            print(f"   ğŸ“ æ ‡é¢˜: {video.get('title', 'æ— ')}")
            print(f"   ğŸ–¼ï¸ ç¼©ç•¥å›¾: {video.get('thumbnail_url', 'æ— ')}")
            print(f"   â±ï¸ æ—¶é•¿: {video.get('relative_time', 'æ— ')}")
    else:
        print("âŒ æœªè§£æåˆ°ä»»ä½•è§†é¢‘")
        
        # è°ƒè¯•ä¿¡æ¯
        soup = BeautifulSoup(html, 'lxml')
        containers = soup.select('.col-xs-6.col-md-3')
        print(f"\nğŸ” è°ƒè¯•ä¿¡æ¯:")
        print(f"   æ‰¾åˆ° {len(containers)} ä¸ª.col-xs-6.col-md-3å®¹å™¨")
        
        if containers:
            container = containers[0]
            print(f"   å®¹å™¨HTMLç¤ºä¾‹:")
            print(f"   {container.prettify()[:300]}...")

if __name__ == "__main__":
    test_parser()